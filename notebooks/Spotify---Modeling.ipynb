{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "np.random.seed(25)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from xgboost import plot_importance\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(\"C://Users//Krishna//Final_data//dataset-of-00s.csv\",header=0,index_col=0)\n",
    "df_2 = pd.read_csv(\"C://Users//Krishna//Final_data//dataset-of-10s.csv\",header=0,index_col=0)\n",
    "df_3 = pd.read_csv(\"C://Users//Krishna//Final_data//dataset-of-60s.csv\",header=0,index_col=0)\n",
    "df_4 = pd.read_csv(\"C://Users//Krishna//Final_data//dataset-of-70s.csv\",header=0,index_col=0)\n",
    "df_5 = pd.read_csv(\"C://Users//Krishna//Final_data//dataset-of-80s.csv\",header=0,index_col=0)\n",
    "df_6 = pd.read_csv(\"C://Users//Krishna//Final_data//dataset-of-90s.csv\",header=0,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatinating the datasets to one dataframe df\n",
    "\n",
    "data= pd.concat([df_1, df_2, df_3, df_4, df_5, df_6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.target\n",
    "x = data[['danceability', 'energy', 'key', 'loudness','mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness','valence', 'tempo', 'duration_ms', 'time_signature', 'chorus_hit','sections']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x_scaler = StandardScaler().fit(x_train)\n",
    "\n",
    "x_train_scaled = x_scaler.transform(x_train)\n",
    "x_test_scaled = x_scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=200, max_depth=25) \n",
    "model = model.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9948425184079924\n",
      "Test score: 0.7857351367130485\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train score: {model.score(x_train_scaled, y_train)}\")\n",
    "print(f\"Test score: {model.score(x_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10287576, 0.08173045, 0.02853718, 0.07805985, 0.01004692,\n",
       "       0.07376693, 0.1138987 , 0.17116731, 0.05071776, 0.06916917,\n",
       "       0.05293697, 0.07310859, 0.00710892, 0.04966541, 0.03721007])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation of feature importance\n",
    "importances = model.feature_importances_\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.17116730720286885, 'instrumentalness'),\n",
       " (0.1138986962097133, 'acousticness'),\n",
       " (0.10287576283304017, 'danceability'),\n",
       " (0.0817304537519217, 'energy'),\n",
       " (0.07805985063695234, 'loudness'),\n",
       " (0.07376692635635022, 'speechiness'),\n",
       " (0.07310859428848573, 'duration_ms'),\n",
       " (0.06916917488348379, 'valence'),\n",
       " (0.052936969585063866, 'tempo'),\n",
       " (0.050717758993032026, 'liveness'),\n",
       " (0.04966540807356965, 'chorus_hit'),\n",
       " (0.03721007215977602, 'sections'),\n",
       " (0.028537182955871425, 'key'),\n",
       " (0.010046918876437218, 'mode'),\n",
       " (0.007108923193433837, 'time_signature')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can sort the features by their importance\n",
    "\n",
    "sorted(zip(model.feature_importances_, x.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.7006901915038397\n",
      "Accuracy: 0.7003989491096624\n"
     ]
    }
   ],
   "source": [
    "#create a baseline decision tree model\n",
    "dct = DecisionTreeClassifier()\n",
    "\n",
    "#fit training set to decision tree model\n",
    "dct.fit(x_train, y_train)\n",
    "\n",
    "#make a prediction\n",
    "\n",
    "y_dct_pred = dct.predict(x_test)\n",
    "\n",
    "f1_score = metrics.f1_score(y_test, y_dct_pred)\n",
    "accuracy = metrics.accuracy_score(y_test, y_dct_pred)\n",
    "\n",
    "print('F1 Score: {}'.format(f1_score))\n",
    "print('Accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09935995, 0.06927255, 0.02307634, 0.05496564, 0.01060348,\n",
       "       0.07623589, 0.10640746, 0.23152248, 0.05018586, 0.06614785,\n",
       "       0.05724669, 0.07408976, 0.0057035 , 0.04800304, 0.0271795 ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation of feature importance\n",
    "importances = dct.feature_importances_\n",
    "importances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.23152247926123634, 'instrumentalness'),\n",
       " (0.10640746339259576, 'acousticness'),\n",
       " (0.09935995327115295, 'danceability'),\n",
       " (0.07623588766745022, 'speechiness'),\n",
       " (0.07408976065194339, 'duration_ms'),\n",
       " (0.0692725538817711, 'energy'),\n",
       " (0.0661478490080949, 'valence'),\n",
       " (0.05724668957256382, 'tempo'),\n",
       " (0.054965640093402636, 'loudness'),\n",
       " (0.05018586406893878, 'liveness'),\n",
       " (0.04800303525703549, 'chorus_hit'),\n",
       " (0.027179504034399574, 'sections'),\n",
       " (0.02307634453438825, 'key'),\n",
       " (0.010603477604287356, 'mode'),\n",
       " (0.005703497700739393, 'time_signature')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can sort the features by their importance\n",
    "\n",
    "sorted(zip(dct.feature_importances_, x.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
